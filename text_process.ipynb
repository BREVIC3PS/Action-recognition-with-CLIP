{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32338c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/169\n",
      "Processing batch 2/169\n",
      "Processing batch 3/169\n",
      "Processing batch 4/169\n",
      "Processing batch 5/169\n",
      "Processing batch 6/169\n",
      "Processing batch 7/169\n",
      "Processing batch 8/169\n",
      "Processing batch 9/169\n",
      "Processing batch 10/169\n",
      "Processing batch 11/169\n",
      "Processing batch 12/169\n",
      "Processing batch 13/169\n",
      "Processing batch 14/169\n",
      "Processing batch 15/169\n",
      "Processing batch 16/169\n",
      "Processing batch 17/169\n",
      "Processing batch 18/169\n",
      "Processing batch 19/169\n",
      "Processing batch 20/169\n",
      "Processing batch 21/169\n",
      "Processing batch 22/169\n",
      "Processing batch 23/169\n",
      "Processing batch 24/169\n",
      "Processing batch 25/169\n",
      "Processing batch 26/169\n",
      "Processing batch 27/169\n",
      "Processing batch 28/169\n",
      "Processing batch 29/169\n",
      "Processing batch 30/169\n",
      "Processing batch 31/169\n",
      "Processing batch 32/169\n",
      "Processing batch 33/169\n",
      "Processing batch 34/169\n",
      "Processing batch 35/169\n",
      "Processing batch 36/169\n",
      "Processing batch 37/169\n",
      "Processing batch 38/169\n",
      "Processing batch 39/169\n",
      "Processing batch 40/169\n",
      "Processing batch 41/169\n",
      "Processing batch 42/169\n",
      "Processing batch 43/169\n",
      "Processing batch 44/169\n",
      "Processing batch 45/169\n",
      "Processing batch 46/169\n",
      "Processing batch 47/169\n",
      "Processing batch 48/169\n",
      "Processing batch 49/169\n",
      "Processing batch 50/169\n",
      "Processing batch 51/169\n",
      "Processing batch 52/169\n",
      "Processing batch 53/169\n",
      "Processing batch 54/169\n",
      "Processing batch 55/169\n",
      "Processing batch 56/169\n",
      "Processing batch 57/169\n",
      "Processing batch 58/169\n",
      "Processing batch 59/169\n",
      "Processing batch 60/169\n",
      "Processing batch 61/169\n",
      "Processing batch 62/169\n",
      "Processing batch 63/169\n",
      "Processing batch 64/169\n",
      "Processing batch 65/169\n",
      "Processing batch 66/169\n",
      "Processing batch 67/169\n",
      "Processing batch 68/169\n",
      "Processing batch 69/169\n",
      "Processing batch 70/169\n",
      "Processing batch 71/169\n",
      "Processing batch 72/169\n",
      "Processing batch 73/169\n",
      "Processing batch 74/169\n",
      "Processing batch 75/169\n",
      "Processing batch 76/169\n",
      "Processing batch 77/169\n",
      "Processing batch 78/169\n",
      "Processing batch 79/169\n",
      "Processing batch 80/169\n",
      "Processing batch 81/169\n",
      "Processing batch 82/169\n",
      "Processing batch 83/169\n",
      "Processing batch 84/169\n",
      "Processing batch 85/169\n",
      "Processing batch 86/169\n",
      "Processing batch 87/169\n",
      "Processing batch 88/169\n",
      "Processing batch 89/169\n",
      "Processing batch 90/169\n",
      "Processing batch 91/169\n",
      "Processing batch 92/169\n",
      "Processing batch 93/169\n",
      "Processing batch 94/169\n",
      "Processing batch 95/169\n",
      "Processing batch 96/169\n",
      "Processing batch 97/169\n",
      "Processing batch 98/169\n",
      "Processing batch 99/169\n",
      "Processing batch 100/169\n",
      "Processing batch 101/169\n",
      "Processing batch 102/169\n",
      "Processing batch 103/169\n",
      "Processing batch 104/169\n",
      "Processing batch 105/169\n",
      "Processing batch 106/169\n",
      "Processing batch 107/169\n",
      "Processing batch 108/169\n",
      "Processing batch 109/169\n",
      "Processing batch 110/169\n",
      "Processing batch 111/169\n",
      "Processing batch 112/169\n",
      "Processing batch 113/169\n",
      "Processing batch 114/169\n",
      "Processing batch 115/169\n",
      "Processing batch 116/169\n",
      "Processing batch 117/169\n",
      "Processing batch 118/169\n",
      "Processing batch 119/169\n",
      "Processing batch 120/169\n",
      "Processing batch 121/169\n",
      "Processing batch 122/169\n",
      "Processing batch 123/169\n",
      "Processing batch 124/169\n",
      "Processing batch 125/169\n",
      "Processing batch 126/169\n",
      "Processing batch 127/169\n",
      "Processing batch 128/169\n",
      "Processing batch 129/169\n",
      "Processing batch 130/169\n",
      "Processing batch 131/169\n",
      "Processing batch 132/169\n",
      "Processing batch 133/169\n",
      "Processing batch 134/169\n",
      "Processing batch 135/169\n",
      "Processing batch 136/169\n",
      "Processing batch 137/169\n",
      "Processing batch 138/169\n",
      "Processing batch 139/169\n",
      "Processing batch 140/169\n",
      "Processing batch 141/169\n",
      "Processing batch 142/169\n",
      "Processing batch 143/169\n",
      "Processing batch 144/169\n",
      "Processing batch 145/169\n",
      "Processing batch 146/169\n",
      "Processing batch 147/169\n",
      "Processing batch 148/169\n",
      "Processing batch 149/169\n",
      "Processing batch 150/169\n",
      "Processing batch 151/169\n",
      "Processing batch 152/169\n",
      "Processing batch 153/169\n",
      "Processing batch 154/169\n",
      "Processing batch 155/169\n",
      "Processing batch 156/169\n",
      "Processing batch 157/169\n",
      "Processing batch 158/169\n",
      "Processing batch 159/169\n",
      "Processing batch 160/169\n",
      "Processing batch 161/169\n",
      "Processing batch 162/169\n",
      "Processing batch 163/169\n",
      "Processing batch 164/169\n",
      "Processing batch 165/169\n",
      "Processing batch 166/169\n",
      "Processing batch 167/169\n",
      "Processing batch 168/169\n",
      "Processing batch 169/169\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "def compute_clip_features(text_batch):\n",
    "\n",
    "    # 对所有文本进行预处理\n",
    "    # Pre-process all texts\n",
    "    textss=torch.cat([clip.tokenize(f\"{i}\")for i in text_batch]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        #对文本提取特征值并标准化\n",
    "        #Extract features and normalize them\n",
    "        texts_features = model.encode_text(textss)\n",
    "        texts_features /= texts_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    #以numpy形式返回特征值\n",
    "    return texts_features.cpu().numpy()\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "#按批次进行处理，batch_size可以根据自己机器性能自定义\n",
    "batch_size = 32\n",
    "\n",
    "#设置特征值存放目录\n",
    "# Path where the feature vectors will be stored\n",
    "features_path = Path(\"action_data\") / \"features\"\n",
    "\n",
    "#读取待处理文本 Load texts\n",
    "f=open(\"k400cls.txt\",mode='r+')\n",
    "s=open(\"states.txt\",mode='r+')\n",
    "actions=list()\n",
    "f_contents=f.readlines()\n",
    "s_contents=s.readlines()\n",
    "for i in f_contents:\n",
    "    for j in s_contents:\n",
    "        #嵌入动作和状态文本 Embed action and state desicirption\n",
    "        actions.append(f\"human action of {i} {j}\")\n",
    "        \n",
    "# 计算batch数量 Compute how many batches are needed\n",
    "batches = math.ceil(len(f_contents)*len(s_contents) / batch_size)\n",
    "\n",
    "\n",
    "# 处理所有批次 Process each batch\n",
    "for i in range(batches):\n",
    "    print(f\"Processing batch {i+1}/{batches}\")\n",
    "    batch_ids_path = features_path / f\"{i:010d}.csv\"\n",
    "    batch_features_path = features_path / f\"{i:010d}.npy\"\n",
    "    \n",
    "    # 当该批次未处理时处理该批次并保存 Only do the processing if the batch wasn't processed yet\n",
    "    if not batch_features_path.exists():\n",
    "        try:\n",
    "            # Select the photos for the current batch\n",
    "            batch_files = actions[i*batch_size : (i+1)*batch_size]\n",
    "\n",
    "            # Compute the features and save to a numpy file\n",
    "            batch_features = compute_clip_features(batch_files)\n",
    "            np.save(batch_features_path, batch_features)\n",
    "\n",
    "            # Save the photo IDs to a CSV file\n",
    "            text = [i for i in batch_files]\n",
    "            photo_ids_data = pd.DataFrame(text, columns=['text_content'])\n",
    "            photo_ids_data.to_csv(batch_ids_path, index=False)\n",
    "        except:\n",
    "            # Catch problems with the processing to make the process more robust\n",
    "            print(f'Problem with batch {i}')\n",
    "            \n",
    "# 读取所有处理好的numpy文件 Load all numpy files\n",
    "features_list = [np.load(features_file) for features_file in sorted(features_path.glob(\"*.npy\"))]\n",
    "\n",
    "# 合并所有特征文件 Concatenate the features and store in a merged file\n",
    "features = np.concatenate(features_list)\n",
    "np.save(features_path / \"features.npy\", features)\n",
    "\n",
    "# 合并所有文本文件\n",
    "photo_ids = pd.concat([pd.read_csv(ids_file) for ids_file in sorted(features_path.glob(\"*.csv\"))])\n",
    "photo_ids.to_csv(features_path / \"text_content.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e0b0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
